{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "inputdata = {'x1': 0.04, 'x2': 0.20}\n",
    "\n",
    "# For the input 𝑥1 and 𝑥2(0.04 and 0.20), we need to train the neural network to find the weight 𝑤𝑖(𝑖 = 1,2…6)\n",
    "# 1) Generate initial random weight between (0,1);  \n",
    "\n",
    "\n",
    "# Output data\n",
    "outputdata = {'x1': 0.50}\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Two nodes in the hidden layer: ℎ1, ℎ2 \n",
    "\n",
    "• Initial random weight: 𝑤1, 𝑤2, 𝑤3, 𝑤4, 𝑤5, 𝑤6 \n",
    "\n",
    "• Learning rate: 𝛼 =0.4 \n",
    "\n",
    " The training process in the first round mainly includes: \n",
    "\n",
    "2) In the forward propagation, calculate the output of the node in the output layer \n",
    "3) Calculate the error function \n",
    "4) In the back propagation, use gradient descent to update all weights "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
